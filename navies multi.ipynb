{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total instances in the dataset: 18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "msg=pd.read_csv('Prog 6-data6 (1).csv',names=['message','label']) #Tabular form data\n",
    "print('Total instances in the dataset:',msg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg['labelnum']=msg.label.map({'pos':1,'neg':0})\n",
    "X=msg.message\n",
    "Y=msg.labelnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The message and its label of first 5 instances are listed below\n",
      "I love this sandwich , pos\n",
      "This is an amazing place , pos\n",
      "I feel very good about these beers , pos\n",
      "This is my best work , pos\n",
      "What an awesome view , pos\n"
     ]
    }
   ],
   "source": [
    "print('\\nThe message and its label of first 5 instances are listed below')\n",
    "X5, Y5 = X[0:5], msg.label[0:5]\n",
    "for x, y in zip(X5,Y5):\n",
    "    print(x,',',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset is split into Training and Testing samples\n",
      "Total training instances : 13\n",
      "Total testing instances : 5\n",
      "\n",
      "Total features extracted using CountVectorizer: 44\n",
      "\n",
      "Features for first 5 training instances are listed below\n",
      "   about  am  amazing  an  and  awesome  beers  best  boss  can  ...  tired  \\\n",
      "0      0   0        0   0    0        0      0     0     0    0  ...      0   \n",
      "1      0   0        0   1    0        1      0     0     0    0  ...      0   \n",
      "2      0   0        1   1    0        0      0     0     0    0  ...      0   \n",
      "3      0   0        0   0    0        0      0     0     0    0  ...      0   \n",
      "4      0   0        0   0    0        0      0     0     0    0  ...      0   \n",
      "\n",
      "   to  tomorrow  very  view  we  what  will  with  work  \n",
      "0   0         0     0     0   0     0     0     0     0  \n",
      "1   0         0     0     1   0     1     0     0     0  \n",
      "2   0         0     0     0   0     0     0     0     0  \n",
      "3   0         0     0     0   0     0     0     0     0  \n",
      "4   0         0     0     0   0     1     0     0     0  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "\n",
      "Classstification results of testing samples are given below\n",
      "That is a bad locality to stay -> pos \n",
      "He is my sworn enemy -> pos \n",
      "I am tired of this stuff -> neg \n",
      "I love this sandwich -> pos \n",
      "I went to my enemy's house today -> pos \n",
      "\n",
      "Accuracy metrics\n",
      "Accuracy of the classifer is 0.4\n",
      "Recall : 1.0 \n",
      "Precison : 0.25\n",
      "Confusion matrix\n",
      "[[1 3]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X,Y)\n",
    "print('\\nDataset is split into Training and Testing samples')\n",
    "print('Total training instances :', xtrain.shape[0])\n",
    "print('Total testing instances :', xtest.shape[0])\n",
    "# Output of count vectoriser is a sparse matrix\n",
    "\n",
    "# CountVectorizer - stands for 'feature extraction'\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "xtrain_dtm = count_vect.fit_transform(xtrain) #Sparse matrix\n",
    "xtest_dtm = count_vect.transform(xtest)\n",
    "print('\\nTotal features extracted using CountVectorizer:',xtrain_dtm.shape[1])\n",
    "\n",
    "\n",
    "print('\\nFeatures for first 5 training instances are listed below')\n",
    "df=pd.DataFrame(xtrain_dtm.toarray(),columns=count_vect.get_feature_names())\n",
    "print(df[0:5])#tabular representation\n",
    "#print(xtrain_dtm) #Same as above but sparse matrix representation\n",
    "# Training Naive Bayes (NB) classifier on training data.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(xtrain_dtm,ytrain)\n",
    "predicted = clf.predict(xtest_dtm)\n",
    "print('\\nClassstification results of testing samples are given below')\n",
    "for doc, p in zip(xtest, predicted):\n",
    "    pred = 'pos' if p==1 else 'neg'\n",
    "    print('%s -> %s ' % (doc, pred))\n",
    "#printing accuracy metrics\n",
    "from sklearn import metrics\n",
    "print('\\nAccuracy metrics')\n",
    "print('Accuracy of the classifer is',metrics.accuracy_score(ytest,predicted))\n",
    "print('Recall :',metrics.recall_score(ytest,predicted),\n",
    "'\\nPrecison :',metrics.precision_score(ytest,predicted))\n",
    "print('Confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest,predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
